{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/appuser/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "## register the dataset \n",
    "# The raw dataset in full resolution\n",
    "#register_coco_instances(\"pascal_raw_train_raw\", {}, \"/pascal_raw/json_annotation_train.json\", \"/pascal_raw/pascal_raw/original/raw\")\n",
    "#register_coco_instances(\"pascal_raw_val_raw\", {}, \"/pascal_raw/json_annotation_val.json\", \"/pascal_raw/pascal_raw/original/raw\")\n",
    "## The jpg dataset in full resolution\n",
    "#register_coco_instances(\"pascal_raw_train_jpg\", {}, \"/pascal_raw/json_annotation_train.json\", \"/pascal_raw/pascal_raw/original/jpg\")\n",
    "#register_coco_instances(\"pascal_raw_val_jpg\", {}, \"/pascal_raw/json_annotation_val.json\", \"/pascal_raw/pascal_raw/original/jpg\")\n",
    "# register the downsampled set\n",
    "register_coco_instances(\"pascal_raw_train_jpg_downsampled\", {}, \"/pascal_raw/pascal_raw_train.json\", \"/pascal_raw/pascal_raw/jpg\")\n",
    "register_coco_instances(\"pascal_raw_val_jpg_downsampled\", {}, \"/pascal_raw/pascal_raw_val.json\", \"/pascal_raw/pascal_raw/jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"configs/faster_rcnn_R_50_FPN_1x.yaml\")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"pascal_raw_train_jpg_downsampled\",)\n",
    "cfg.DATASETS.TEST = (\"pascal_raw_val_jpg_downsampled\",)\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300 \n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_zoo.get_config_file()\n",
    "\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"configs/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"configs/faster_rcnn_R_50_FPN_1x.yaml\")  # Let training initialize from model zoo\n",
    "   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "# only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/23 09:28:39 d2.engine.defaults]: Model:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/23 09:28:39 d2.data.datasets.coco]: Loaded 2126 images in COCO format from /pascal_raw/pascal_raw_train.json\n",
      "[11/23 09:28:39 d2.data.build]: Removed 0 images with no usable annotations. 2126 images left.\n",
      "[11/23 09:28:39 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "[11/23 09:28:39 d2.data.build]: Using training sampler TrainingSampler\n",
      "[11/23 09:28:39 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "[11/23 09:28:39 d2.data.common]: Serializing 2126 elements to byte tensors and concatenating them all ...\n",
      "[11/23 09:28:39 d2.data.common]: Serialized dataset takes 0.54 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
      "roi_heads.box_predictor.cls_score.{bias, weight}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/23 09:28:39 d2.engine.train_loop]: Starting training from iteration 0\n",
      "[11/23 09:28:47 d2.utils.events]:  eta: 0:01:41  iter: 19  total_loss: 1.596  loss_cls: 1.447  loss_box_reg: 0.1345  loss_rpn_cls: 0.005855  loss_rpn_loc: 0.005591  time: 0.3582  data_time: 0.0272  lr: 1.6068e-05  max_mem: 2999M\n",
      "[11/23 09:28:54 d2.utils.events]:  eta: 0:01:38  iter: 39  total_loss: 1.319  loss_cls: 1.152  loss_box_reg: 0.1439  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.01072  time: 0.3677  data_time: 0.0066  lr: 3.2718e-05  max_mem: 2999M\n",
      "[11/23 09:29:02 d2.utils.events]:  eta: 0:01:30  iter: 59  total_loss: 0.841  loss_cls: 0.6816  loss_box_reg: 0.1539  loss_rpn_cls: 0.006425  loss_rpn_loc: 0.00792  time: 0.3681  data_time: 0.0057  lr: 4.9367e-05  max_mem: 2999M\n",
      "[11/23 09:29:09 d2.utils.events]:  eta: 0:01:21  iter: 79  total_loss: 0.5135  loss_cls: 0.3391  loss_box_reg: 0.1608  loss_rpn_cls: 0.007274  loss_rpn_loc: 0.007927  time: 0.3672  data_time: 0.0062  lr: 6.6017e-05  max_mem: 2999M\n",
      "[11/23 09:29:17 d2.utils.events]:  eta: 0:01:15  iter: 99  total_loss: 0.4367  loss_cls: 0.2456  loss_box_reg: 0.1859  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.009034  time: 0.3714  data_time: 0.0060  lr: 8.2668e-05  max_mem: 2999M\n",
      "[11/23 09:29:24 d2.utils.events]:  eta: 0:01:07  iter: 119  total_loss: 0.3157  loss_cls: 0.1571  loss_box_reg: 0.1441  loss_rpn_cls: 0.004747  loss_rpn_loc: 0.005917  time: 0.3708  data_time: 0.0056  lr: 9.9318e-05  max_mem: 2999M\n",
      "[11/23 09:29:32 d2.utils.events]:  eta: 0:01:00  iter: 139  total_loss: 0.274  loss_cls: 0.1298  loss_box_reg: 0.134  loss_rpn_cls: 0.006058  loss_rpn_loc: 0.004763  time: 0.3718  data_time: 0.0060  lr: 0.00011597  max_mem: 2999M\n",
      "[11/23 09:29:39 d2.utils.events]:  eta: 0:00:52  iter: 159  total_loss: 0.2569  loss_cls: 0.1137  loss_box_reg: 0.1364  loss_rpn_cls: 0.002841  loss_rpn_loc: 0.005985  time: 0.3713  data_time: 0.0057  lr: 0.00013262  max_mem: 2999M\n",
      "[11/23 09:29:47 d2.utils.events]:  eta: 0:00:44  iter: 179  total_loss: 0.2693  loss_cls: 0.1117  loss_box_reg: 0.1496  loss_rpn_cls: 0.003757  loss_rpn_loc: 0.004038  time: 0.3713  data_time: 0.0053  lr: 0.00014927  max_mem: 2999M\n",
      "[11/23 09:29:54 d2.utils.events]:  eta: 0:00:37  iter: 199  total_loss: 0.3001  loss_cls: 0.1177  loss_box_reg: 0.1757  loss_rpn_cls: 0.002886  loss_rpn_loc: 0.006116  time: 0.3698  data_time: 0.0051  lr: 0.00016592  max_mem: 2999M\n",
      "[11/23 09:30:01 d2.utils.events]:  eta: 0:00:29  iter: 219  total_loss: 0.2621  loss_cls: 0.1081  loss_box_reg: 0.143  loss_rpn_cls: 0.001535  loss_rpn_loc: 0.003456  time: 0.3686  data_time: 0.0048  lr: 0.00018257  max_mem: 2999M\n",
      "[11/23 09:30:08 d2.utils.events]:  eta: 0:00:22  iter: 239  total_loss: 0.2881  loss_cls: 0.1171  loss_box_reg: 0.176  loss_rpn_cls: 0.002092  loss_rpn_loc: 0.005458  time: 0.3682  data_time: 0.0057  lr: 0.00019922  max_mem: 2999M\n",
      "[11/23 09:30:16 d2.utils.events]:  eta: 0:00:14  iter: 259  total_loss: 0.2701  loss_cls: 0.1035  loss_box_reg: 0.16  loss_rpn_cls: 0.005051  loss_rpn_loc: 0.004927  time: 0.3684  data_time: 0.0051  lr: 0.00021587  max_mem: 2999M\n",
      "[11/23 09:30:23 d2.utils.events]:  eta: 0:00:07  iter: 279  total_loss: 0.2746  loss_cls: 0.1022  loss_box_reg: 0.1589  loss_rpn_cls: 0.004665  loss_rpn_loc: 0.004653  time: 0.3677  data_time: 0.0052  lr: 0.00023252  max_mem: 2999M\n",
      "[11/23 09:30:31 d2.utils.events]:  eta: 0:00:00  iter: 299  total_loss: 0.2493  loss_cls: 0.08736  loss_box_reg: 0.1514  loss_rpn_cls: 0.001285  loss_rpn_loc: 0.00368  time: 0.3677  data_time: 0.0058  lr: 0.00024917  max_mem: 2999M\n",
      "[11/23 09:30:31 d2.engine.hooks]: Overall training speed: 298 iterations in 0:01:49 (0.3677 s / it)\n",
      "[11/23 09:30:31 d2.engine.hooks]: Total training time: 0:01:50 (0:00:00 on hooks)\n",
      "[11/23 09:30:31 d2.data.datasets.coco]: Loaded 2127 images in COCO format from /pascal_raw/pascal_raw_val.json\n",
      "[11/23 09:30:31 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[11/23 09:30:31 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "[11/23 09:30:31 d2.data.common]: Serializing 2127 elements to byte tensors and concatenating them all ...\n",
      "[11/23 09:30:31 d2.data.common]: Serialized dataset takes 0.54 MiB\n",
      "WARNING [11/23 09:30:31 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'type' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOCOEvaluator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/detectron2_repo/detectron2/engine/defaults.py:596\u001b[0m, in \u001b[0;36mDefaultTrainer.test\u001b[0;34m(cls, cfg, model, evaluators)\u001b[0m\n\u001b[1;32m    594\u001b[0m     evaluators \u001b[38;5;241m=\u001b[39m [evaluators]\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evaluators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;28mlen\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST), \u001b[38;5;28mlen\u001b[39m(evaluators)\n\u001b[1;32m    598\u001b[0m     )\n\u001b[1;32m    600\u001b[0m results \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, dataset_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST):\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'type' has no len()"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/23 09:34:38 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n",
      "[11/23 09:34:38 d2.data.datasets.coco]: Loaded 2127 images in COCO format from /pascal_raw/pascal_raw_val.json\n",
      "[11/23 09:34:38 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[11/23 09:34:38 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "[11/23 09:34:38 d2.data.common]: Serializing 2127 elements to byte tensors and concatenating them all ...\n",
      "[11/23 09:34:38 d2.data.common]: Serialized dataset takes 0.54 MiB\n",
      "[11/23 09:34:38 d2.evaluation.evaluator]: Start inference on 2127 batches\n",
      "[11/23 09:34:40 d2.evaluation.evaluator]: Inference done 11/2127. Dataloading: 0.0034 s/iter. Inference: 0.0869 s/iter. Eval: 0.0003 s/iter. Total: 0.0906 s/iter. ETA=0:03:11\n",
      "[11/23 09:34:45 d2.evaluation.evaluator]: Inference done 62/2127. Dataloading: 0.0102 s/iter. Inference: 0.0875 s/iter. Eval: 0.0005 s/iter. Total: 0.0983 s/iter. ETA=0:03:23\n",
      "[11/23 09:34:50 d2.evaluation.evaluator]: Inference done 112/2127. Dataloading: 0.0113 s/iter. Inference: 0.0875 s/iter. Eval: 0.0004 s/iter. Total: 0.0994 s/iter. ETA=0:03:20\n",
      "[11/23 09:34:55 d2.evaluation.evaluator]: Inference done 167/2127. Dataloading: 0.0088 s/iter. Inference: 0.0877 s/iter. Eval: 0.0004 s/iter. Total: 0.0970 s/iter. ETA=0:03:10\n",
      "[11/23 09:35:00 d2.evaluation.evaluator]: Inference done 223/2127. Dataloading: 0.0072 s/iter. Inference: 0.0877 s/iter. Eval: 0.0004 s/iter. Total: 0.0954 s/iter. ETA=0:03:01\n",
      "[11/23 09:35:05 d2.evaluation.evaluator]: Inference done 278/2127. Dataloading: 0.0063 s/iter. Inference: 0.0878 s/iter. Eval: 0.0004 s/iter. Total: 0.0946 s/iter. ETA=0:02:54\n",
      "[11/23 09:35:10 d2.evaluation.evaluator]: Inference done 331/2127. Dataloading: 0.0064 s/iter. Inference: 0.0879 s/iter. Eval: 0.0004 s/iter. Total: 0.0948 s/iter. ETA=0:02:50\n",
      "[11/23 09:35:15 d2.evaluation.evaluator]: Inference done 383/2127. Dataloading: 0.0068 s/iter. Inference: 0.0879 s/iter. Eval: 0.0004 s/iter. Total: 0.0952 s/iter. ETA=0:02:46\n",
      "[11/23 09:35:20 d2.evaluation.evaluator]: Inference done 433/2127. Dataloading: 0.0073 s/iter. Inference: 0.0880 s/iter. Eval: 0.0004 s/iter. Total: 0.0958 s/iter. ETA=0:02:42\n",
      "[11/23 09:35:25 d2.evaluation.evaluator]: Inference done 487/2127. Dataloading: 0.0070 s/iter. Inference: 0.0880 s/iter. Eval: 0.0004 s/iter. Total: 0.0955 s/iter. ETA=0:02:36\n",
      "[11/23 09:35:30 d2.evaluation.evaluator]: Inference done 542/2127. Dataloading: 0.0067 s/iter. Inference: 0.0880 s/iter. Eval: 0.0004 s/iter. Total: 0.0952 s/iter. ETA=0:02:30\n",
      "[11/23 09:35:35 d2.evaluation.evaluator]: Inference done 596/2127. Dataloading: 0.0064 s/iter. Inference: 0.0881 s/iter. Eval: 0.0004 s/iter. Total: 0.0951 s/iter. ETA=0:02:25\n",
      "[11/23 09:35:40 d2.evaluation.evaluator]: Inference done 647/2127. Dataloading: 0.0063 s/iter. Inference: 0.0885 s/iter. Eval: 0.0004 s/iter. Total: 0.0953 s/iter. ETA=0:02:21\n",
      "[11/23 09:35:45 d2.evaluation.evaluator]: Inference done 698/2127. Dataloading: 0.0063 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.0956 s/iter. ETA=0:02:16\n",
      "[11/23 09:35:50 d2.evaluation.evaluator]: Inference done 748/2127. Dataloading: 0.0065 s/iter. Inference: 0.0889 s/iter. Eval: 0.0004 s/iter. Total: 0.0959 s/iter. ETA=0:02:12\n",
      "[11/23 09:35:55 d2.evaluation.evaluator]: Inference done 794/2127. Dataloading: 0.0073 s/iter. Inference: 0.0889 s/iter. Eval: 0.0004 s/iter. Total: 0.0967 s/iter. ETA=0:02:08\n",
      "[11/23 09:36:00 d2.evaluation.evaluator]: Inference done 837/2127. Dataloading: 0.0082 s/iter. Inference: 0.0890 s/iter. Eval: 0.0004 s/iter. Total: 0.0977 s/iter. ETA=0:02:06\n",
      "[11/23 09:36:05 d2.evaluation.evaluator]: Inference done 873/2127. Dataloading: 0.0100 s/iter. Inference: 0.0889 s/iter. Eval: 0.0004 s/iter. Total: 0.0995 s/iter. ETA=0:02:04\n",
      "[11/23 09:36:10 d2.evaluation.evaluator]: Inference done 910/2127. Dataloading: 0.0117 s/iter. Inference: 0.0889 s/iter. Eval: 0.0004 s/iter. Total: 0.1011 s/iter. ETA=0:02:02\n",
      "[11/23 09:36:16 d2.evaluation.evaluator]: Inference done 949/2127. Dataloading: 0.0129 s/iter. Inference: 0.0888 s/iter. Eval: 0.0004 s/iter. Total: 0.1022 s/iter. ETA=0:02:00\n",
      "[11/23 09:36:21 d2.evaluation.evaluator]: Inference done 994/2127. Dataloading: 0.0134 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.1026 s/iter. ETA=0:01:56\n",
      "[11/23 09:36:26 d2.evaluation.evaluator]: Inference done 1030/2127. Dataloading: 0.0146 s/iter. Inference: 0.0888 s/iter. Eval: 0.0004 s/iter. Total: 0.1040 s/iter. ETA=0:01:54\n",
      "[11/23 09:36:31 d2.evaluation.evaluator]: Inference done 1064/2127. Dataloading: 0.0162 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.1054 s/iter. ETA=0:01:52\n",
      "[11/23 09:36:36 d2.evaluation.evaluator]: Inference done 1114/2127. Dataloading: 0.0160 s/iter. Inference: 0.0886 s/iter. Eval: 0.0004 s/iter. Total: 0.1052 s/iter. ETA=0:01:46\n",
      "[11/23 09:36:41 d2.evaluation.evaluator]: Inference done 1166/2127. Dataloading: 0.0159 s/iter. Inference: 0.0886 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:01:40\n",
      "[11/23 09:36:46 d2.evaluation.evaluator]: Inference done 1219/2127. Dataloading: 0.0155 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:01:35\n",
      "[11/23 09:36:51 d2.evaluation.evaluator]: Inference done 1266/2127. Dataloading: 0.0156 s/iter. Inference: 0.0886 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:01:30\n",
      "[11/23 09:36:56 d2.evaluation.evaluator]: Inference done 1304/2127. Dataloading: 0.0164 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.1056 s/iter. ETA=0:01:26\n",
      "[11/23 09:37:01 d2.evaluation.evaluator]: Inference done 1343/2127. Dataloading: 0.0172 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.1064 s/iter. ETA=0:01:23\n",
      "[11/23 09:37:07 d2.evaluation.evaluator]: Inference done 1379/2127. Dataloading: 0.0182 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.1074 s/iter. ETA=0:01:20\n",
      "[11/23 09:37:12 d2.evaluation.evaluator]: Inference done 1423/2127. Dataloading: 0.0184 s/iter. Inference: 0.0886 s/iter. Eval: 0.0004 s/iter. Total: 0.1076 s/iter. ETA=0:01:15\n",
      "[11/23 09:37:17 d2.evaluation.evaluator]: Inference done 1460/2127. Dataloading: 0.0191 s/iter. Inference: 0.0887 s/iter. Eval: 0.0004 s/iter. Total: 0.1084 s/iter. ETA=0:01:12\n",
      "[11/23 09:37:22 d2.evaluation.evaluator]: Inference done 1491/2127. Dataloading: 0.0202 s/iter. Inference: 0.0888 s/iter. Eval: 0.0004 s/iter. Total: 0.1095 s/iter. ETA=0:01:09\n",
      "[11/23 09:37:27 d2.evaluation.evaluator]: Inference done 1524/2127. Dataloading: 0.0210 s/iter. Inference: 0.0889 s/iter. Eval: 0.0004 s/iter. Total: 0.1105 s/iter. ETA=0:01:06\n",
      "[11/23 09:37:32 d2.evaluation.evaluator]: Inference done 1573/2127. Dataloading: 0.0208 s/iter. Inference: 0.0889 s/iter. Eval: 0.0004 s/iter. Total: 0.1103 s/iter. ETA=0:01:01\n",
      "[11/23 09:37:37 d2.evaluation.evaluator]: Inference done 1621/2127. Dataloading: 0.0206 s/iter. Inference: 0.0890 s/iter. Eval: 0.0004 s/iter. Total: 0.1101 s/iter. ETA=0:00:55\n",
      "[11/23 09:37:42 d2.evaluation.evaluator]: Inference done 1672/2127. Dataloading: 0.0200 s/iter. Inference: 0.0892 s/iter. Eval: 0.0004 s/iter. Total: 0.1098 s/iter. ETA=0:00:49\n",
      "[11/23 09:37:47 d2.evaluation.evaluator]: Inference done 1724/2127. Dataloading: 0.0198 s/iter. Inference: 0.0892 s/iter. Eval: 0.0004 s/iter. Total: 0.1095 s/iter. ETA=0:00:44\n",
      "[11/23 09:37:52 d2.evaluation.evaluator]: Inference done 1772/2127. Dataloading: 0.0197 s/iter. Inference: 0.0892 s/iter. Eval: 0.0004 s/iter. Total: 0.1094 s/iter. ETA=0:00:38\n",
      "[11/23 09:37:57 d2.evaluation.evaluator]: Inference done 1810/2127. Dataloading: 0.0203 s/iter. Inference: 0.0891 s/iter. Eval: 0.0004 s/iter. Total: 0.1099 s/iter. ETA=0:00:34\n",
      "[11/23 09:38:03 d2.evaluation.evaluator]: Inference done 1862/2127. Dataloading: 0.0200 s/iter. Inference: 0.0891 s/iter. Eval: 0.0004 s/iter. Total: 0.1096 s/iter. ETA=0:00:29\n",
      "[11/23 09:38:08 d2.evaluation.evaluator]: Inference done 1918/2127. Dataloading: 0.0194 s/iter. Inference: 0.0890 s/iter. Eval: 0.0004 s/iter. Total: 0.1090 s/iter. ETA=0:00:22\n",
      "[11/23 09:38:13 d2.evaluation.evaluator]: Inference done 1973/2127. Dataloading: 0.0190 s/iter. Inference: 0.0890 s/iter. Eval: 0.0004 s/iter. Total: 0.1085 s/iter. ETA=0:00:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/23 09:38:18 d2.evaluation.evaluator]: Inference done 2028/2127. Dataloading: 0.0186 s/iter. Inference: 0.0890 s/iter. Eval: 0.0004 s/iter. Total: 0.1081 s/iter. ETA=0:00:10\n",
      "[11/23 09:38:23 d2.evaluation.evaluator]: Inference done 2080/2127. Dataloading: 0.0183 s/iter. Inference: 0.0890 s/iter. Eval: 0.0004 s/iter. Total: 0.1078 s/iter. ETA=0:00:05\n",
      "[11/23 09:38:27 d2.evaluation.evaluator]: Total inference time: 0:03:48.164765 (0.107523 s / iter per device, on 1 devices)\n",
      "[11/23 09:38:27 d2.evaluation.evaluator]: Total inference pure compute time: 0:03:08 (0.088941 s / iter per device, on 1 devices)\n",
      "[11/23 09:38:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[11/23 09:38:28 d2.evaluation.coco_evaluation]: Saving results to ./output/coco_instances_results.json\n",
      "[11/23 09:38:28 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.57s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.85s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.425\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.589\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.624\n",
      "[11/23 09:38:32 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 38.473 | 63.819 | 42.544 | 9.871 | 27.799 | 41.662 |\n",
      "[11/23 09:38:32 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP    | category   | AP     | category   | AP     |\n",
      "|:-----------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| bicycle    | 3.339 | car        | 57.416 | person     | 54.662 |\n",
      "[11/23 09:38:32 d2.engine.defaults]: Evaluation results for pascal_raw_val_jpg_downsampled in csv format:\n",
      "[11/23 09:38:32 d2.evaluation.testing]: copypaste: Task: bbox\n",
      "[11/23 09:38:32 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
      "[11/23 09:38:32 d2.evaluation.testing]: copypaste: 38.4725,63.8192,42.5440,9.8707,27.7987,41.6621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 38.47251097374951,\n",
       "               'AP50': 63.81919533926015,\n",
       "               'AP75': 42.54397837722831,\n",
       "               'APs': 9.870699564180521,\n",
       "               'APm': 27.79871010290321,\n",
       "               'APl': 41.662097757379755,\n",
       "               'AP-bicycle': 3.3391498427242836,\n",
       "               'AP-car': 57.4164216657729,\n",
       "               'AP-person': 54.66196141275136})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=trainer.model, cfg=cfg, evaluators=[COCOEvaluator(\"pascal_raw_val_jpg_downsampled\", output_dir=cfg.OUTPUT_DIR),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
